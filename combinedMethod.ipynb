{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "combinedMethod.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kU_e8YObKZV",
        "outputId": "a49898c0-bc15-46d4-de2b-9c8f06edaefd"
      },
      "source": [
        "# SET VIDEO ID HERE\n",
        "videoID = 'Maia_Fall' \n",
        "personThresh = 0.8\n",
        "videoPath='/content/drive/My Drive/DL_CV_FinalProject/Datasets/our_fall_dataset/'+ videoID + '.MOV'\n",
        "print(videoPath)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "rootPath = '/content/drive/My Drive/DL_CV_FinalProject/'\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DL_CV_FinalProject/Datasets/our_fall_dataset/Maia_Fall.MOV\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggpthOSdBFWy"
      },
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab\n",
        "assert torch.__version__.startswith(\"1.7\")\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.7/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-6FOICnBroB"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "#from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "import sys\n",
        "import time\n",
        "import pickle\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTlcHqkFh6p4"
      },
      "source": [
        "## Check for GPU \n",
        "gpu_check = torch.cuda.is_available()\n",
        "print(gpu_check)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qA-ZqeHNw9c"
      },
      "source": [
        "## Initialize class for predictor functions\n",
        "class ReturnPredictions(object):\n",
        "    def __init__(self,cfg):\n",
        "        self.predictor = DefaultPredictor(cfg)\n",
        "        self.metadata = MetadataCatalog.get(\n",
        "                cfg.DATASETS.TEST[0] if len(cfg.DATASETS.TEST) else \"__unused\")\n",
        "\n",
        "    def _frame_from_video(self,video):\n",
        "        print(video)\n",
        "        while video.isOpened():\n",
        "            success,frame = video.read()\n",
        "            if success:\n",
        "                yield frame\n",
        "            else:\n",
        "                break\n",
        "\n",
        "    def run_on_video(self,video):\n",
        "        frame_gen = self._frame_from_video(video)\n",
        "        for frame in frame_gen:\n",
        "            \n",
        "            yield self.predictor(frame),frame\n",
        "\n",
        "    def run_on_image(self,image):\n",
        "      # Convert image from OpenCV BGR format to Matplotlib RGB format.\n",
        "      yield self.predictor(image)\n",
        "\n",
        "\n",
        "## Load and setup model and predictor\n",
        "cfg = get_cfg()\n",
        "\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "predictor = ReturnPredictions(cfg)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s849oNYt6EJ1"
      },
      "source": [
        "def resizeImg(orig_frame, scale):\n",
        "  # resize input image to lower dimensionality\n",
        "  width = int(orig_frame.shape[1] * scale)\n",
        "  height = int(orig_frame.shape[0] * scale)\n",
        "  dim = (width, height)\n",
        "  resized = cv2.resize(orig_frame, dim, interpolation = cv2.INTER_AREA)\n",
        "  return resized\n",
        "\n",
        "def resizeKPB(keyPoints,bbox, scale):\n",
        "  # rescale keypoints and bounding boxes to match new image dimensions \n",
        "  keyPoints[:,:-1] = keyPoints[:,:-1]*scale\n",
        "  bbox = bbox*scale\n",
        "  return keyPoints,bbox\n",
        "\n",
        "def removeOutliers(signal,scale_lower=1,scale_upper=3):\n",
        "  # for cases where no box detected, remove \n",
        "  avg = np.mean(signal)\n",
        "  std = np.std(signal)\n",
        "  upper = avg+scale_upper*std # upper is scale_upper std from the mean\n",
        "  lower = avg-scale_lower*std # lower is scale_lower std from the mean\n",
        "  \n",
        "\n",
        "  # only return values where the input is greater than the lower threshold and less than the upper \n",
        "  out = signal[np.logical_and(signal>lower,signal<upper)]\n",
        "  #out = signal[signal>lower]\n",
        "  \n",
        "  return out\n",
        "\n",
        "# def removeOutliers_bbox(signal,scale_lower=1,scale_upper=1):\n",
        "#   avg = np.mean(signal)\n",
        "#   std = np.std(signal)\n",
        "#   upper = avg+scale_upper*std\n",
        "#   lower = avg-scale_lower*std\n",
        "\n",
        "#   out = signal[np.logical_and(signal>lower,signal<upper)]\n",
        "#   #out = signal[signal>lower]\n",
        "  \n",
        "#   return out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXU7DejOCSkS"
      },
      "source": [
        "storeKeypoints = [] \n",
        "storeFrames = [] # store grayscale frames\n",
        "storeBBox = []\n",
        "storeFlow = []\n",
        "\n",
        "# arrays of 0s to append when no person present \n",
        "noPointsArray = np.zeros((17,3))\n",
        "noBoxArray = np.zeros(4)\n",
        "\n",
        "# create detectron points and bounding box generator \n",
        "vid = cv2.VideoCapture(videoPath)\n",
        "output_generator = predictor.run_on_video(vid) \n",
        "\n",
        "imgID = 0\n",
        "\n",
        "# iterate through frames \n",
        "for output_frame in output_generator:\n",
        "\n",
        "  # scale factor = how much to decrease dimensionality --> helps with OF compute needed \n",
        "  scale_factor = 0.3\n",
        "\n",
        "  print('---------------- Image Number: ',imgID)\n",
        "  output = output_frame[0]\n",
        "  frame = output_frame[1]\n",
        "\n",
        "  # scale image down \n",
        "  g_frame = resizeImg(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY),scale_factor)\n",
        "  storeFrames.append(g_frame)\n",
        "\n",
        "  # extract values from output \n",
        "  personScore = output['instances'].scores.cpu().numpy()\n",
        "  keypoints_all = output['instances'].pred_keypoints.cpu().numpy()\n",
        "  person_scores = output['instances'].scores.cpu().numpy()\n",
        "  bound_box = output['instances'].pred_boxes.tensor.cpu().numpy()\n",
        "\n",
        "  # extract indices of cases where person is detected \n",
        "  idx_scores_valid = np.argwhere(person_scores>personThresh)\n",
        "\n",
        "  # skip the first frame \n",
        "  if imgID == 0:\n",
        "    storeKeypoints.append(noPointsArray)\n",
        "    storeBBox.append(noBoxArray)\n",
        "    imgID += 1\n",
        "    continue\n",
        "\n",
        "  imgID += 1\n",
        "\n",
        "  # calculate Dense Optical Flow between current image and previous image \n",
        "  flow = cv2.calcOpticalFlowFarneback(storeFrames[-2], storeFrames[-1], None, 0.5, 3, 25, 3, 5, 1.2, 0)\n",
        "\n",
        "  if len(idx_scores_valid) == 0:\n",
        "    # if no person detected \n",
        "\n",
        "    print('Could not detect person!')\n",
        "    storeKeypoints.append(noPointsArray)\n",
        "    storeBBox.append(noBoxArray)\n",
        "\n",
        "    # magnitude based on all pixels in image\n",
        "    u = flow[:,:,0]\n",
        "    v = flow[:,:,1]\n",
        "\n",
        "    # get magnitude, remove outliers, then take mean \n",
        "    flow_mag = np.mean(removeOutliers(np.sqrt(u ** 2 + v ** 2),scale_lower=1,scale_upper=3))\n",
        "\n",
        "    storeFlow.append(flow_mag)\n",
        "  else:    \n",
        "    print(\"All Scores:\",person_scores)\n",
        "\n",
        "    # resize RGB image for showing figure \n",
        "    imgCopy = resizeImg(cv2.cvtColor(frame.copy(),cv2.COLOR_BGR2RGB),scale_factor)\n",
        "\n",
        "    # resize kps and bboxes \n",
        "    key,box = resizeKPB(keypoints_all[np.argmax(person_scores)],\n",
        "                        bound_box[np.argmax(person_scores)], \n",
        "                        scale_factor)\n",
        "\n",
        "    # extract pixels that are within the bounding box of the current frame \n",
        "    u = flow[int(box[1]):int(box[3]),int(box[0]):int(box[2]),0]\n",
        "    v = flow[int(box[1]):int(box[3]),int(box[0]):int(box[2]),1]\n",
        "\n",
        "    # get magnitude, remove outliers, then take mean \n",
        "    flow_mag = np.mean(removeOutliers(np.sqrt(u ** 2 + v ** 2),scale_lower=2,scale_upper=2))\n",
        "    storeFlow.append(flow_mag)\n",
        "\n",
        "    storeKeypoints.append(key)\n",
        "    storeBBox.append(box)\n",
        "\n",
        "    # draw bounding boxes and key points \n",
        "    cv2.rectangle(imgCopy, (box[0],box[1]), (box[2],box[3]), (255,0,0),2)\n",
        "    for pt in key:\n",
        "      #print('Confidence = ',pt[2])\n",
        "      if pt[2] > 0.1:\n",
        "        cv2.circle(imgCopy, (pt[0],pt[1]), 2, (0,255,0), -1)\n",
        "\n",
        "    plt.imshow(imgCopy,cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    \n",
        "\n",
        "storeKeypoints_ = np.stack(storeKeypoints,axis=0)\n",
        "storeBBox_ = np.stack(storeBBox,axis=0)\n",
        "storeFrames_ = np.stack(storeFrames,axis=0)\n",
        "storeFlow_ = np.array(storeFlow)\n",
        "\n",
        "#### From detectron2 Code ####\n",
        "# COCO_PERSON_KEYPOINT_NAMES = (\n",
        "#     \"nose\",\n",
        "#     \"left_eye\", \"right_eye\",\n",
        "#     \"left_ear\", \"right_ear\",\n",
        "#     \"left_shoulder\", \"right_shoulder\",\n",
        "#     \"left_elbow\", \"right_elbow\",\n",
        "#     \"left_wrist\", \"right_wrist\",\n",
        "#     \"left_hip\", \"right_hip\",\n",
        "#     \"left_knee\", \"right_knee\",\n",
        "#     \"left_ankle\", \"right_ankle\",\n",
        "# )\n",
        "# Frames x 17 x 3 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13G7AdZ873gd"
      },
      "source": [
        "f_plot = np.arange(len(storeFlow_))\n",
        "plt.plot(f_plot,storeFlow_,'k')\n",
        "plt.xlim([0,len(storeFlow_)-1])\n",
        "plt.ylabel('Average Optical Flow Magnitude')\n",
        "plt.xlabel('Frame Number')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}